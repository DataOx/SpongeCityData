{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 15 13:19:13 2019\n",
    "\n",
    "@author: 60888\n",
    "\"\"\"\n",
    "from dataInterfaceAssistant import dataInterfaceClass\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "DIA = dataInterfaceClass()\n",
    "\n",
    "def spongeCityService(start,stop,levelThreshold,maxThreshold,levelSlopeAngle,dataOffset,bufferLength,resultAttribute):\n",
    "    mille = 1000 # magic number that is used to correct Alibaba UNIX time to standard UNIX time\n",
    "    timeRange = [start,stop]\n",
    "    levelThreshold = levelThreshold\n",
    "    levelSlopeAngle = levelSlopeAngle\n",
    "    dataOffset = int(dataOffset)\n",
    "    bufferLength = int(bufferLength)\n",
    "    \n",
    "    # Import data \n",
    "    # parse json data frame to a panda dataframe using: getDataToWorkWith(\"data from the API\")\n",
    "    requestedData, statusInfoRequest, reasonCodeRequest = DIA.getDataToWorkWith(timeRange)\n",
    "    #print(len(requestedData))\n",
    "    #print(statusInfoRequest)#, reasonCodeRequest)\n",
    "    #print(requestedData)\n",
    "    # convert it (if you like) to a panda dataframe for algoritmic convinience: postProcessedDataBack(\"your converted data\")\n",
    "    requestedDataframe = DIA.jsonToDataframe(requestedData, resultAttribute)\n",
    "    # Do basic repair\n",
    "    requestedDataframe.isnull().values.any()\n",
    "    # mirror baseline input to output and change only what you need to change\n",
    "    processedDataframe = requestedDataframe\n",
    "    \n",
    "    \"\"\" ####### Do the data \"magic\" ########### \"\"\" \n",
    "    # Remember to add unit test of this particular piece of code - sanity check is only done on data request and data post\n",
    "    degree = 1\n",
    "    linearRegressionModel = linear_model.LinearRegression()\n",
    "  \n",
    "    for timeIndex in range(0, len(requestedDataframe.get('water_level').values[dataOffset:])-bufferLength, bufferLength):\n",
    "        \n",
    "        # Get data to work with\n",
    "        x = requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].reshape(len(requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]), 1)\n",
    "        y = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].reshape(len(requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]), 1)\n",
    "        x = np.divide(x, mille)\n",
    "        \n",
    "        xx = requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].astype('int')\n",
    "        yy = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].astype('float')\n",
    "        xx = np.divide(xx, mille)\n",
    "        \n",
    "        # Make line fit / linear regression\n",
    "        weights = np.polyfit(np.array(xx),np.array(yy), degree)\n",
    "        model = np.poly1d(weights)\n",
    "        \n",
    "        #linearRegressionModel.fit(x,y)\n",
    "        #linearRegressionModelPrediction = linearRegressionModel.predict(list(test.get('time').values))\n",
    "        \n",
    "        #bufferSlope = math.degrees(math.atan(linearRegressionModel.coef_))\n",
    "        bufferSlope = weights[0]\n",
    "        #bufferMean = np.mean(y)\n",
    "        bufferMean = np.mean(yy)\n",
    "\n",
    "        # Make primitive overflow classification\n",
    "        if bufferMean >= levelThreshold and bufferSlope > levelSlopeAngle:\n",
    "            #print('yes')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]\n",
    "        elif bufferMean >= maxThreshold and bufferSlope >= 0:\n",
    "            #print('yes')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]\n",
    "        else:\n",
    "            #print('no')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = float(-1)\n",
    "            \n",
    "    \"\"\" ####### Please stop your \"magic\" ########### \"\"\"    \n",
    "    # Export data\n",
    "    processedData = DIA.dataframeToJson(processedDataframe)\n",
    "    #print(processedData)\n",
    "    # ship it away with: postProcessedDataBack(\"your converted data\")\n",
    "    statusInfoPost, reasonCodePost = DIA.postProcessedDataBack(processedData)\n",
    "    #print(statusInfoPost)#, reasonCode)\n",
    "    if(statusInfoRequest == DIA.sanityCheck() and statusInfoPost == DIA.sanityCheck() and len(requestedData) > 0):\n",
    "        sanityCheck = True\n",
    "    else:\n",
    "        sanityCheck = False\n",
    "            \n",
    "    print(\"The operation went well:\", sanityCheck)\n",
    "    return processedDataframe, sanityCheck\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    timeOffset = 72 # Number of hours to take into account in the overflow post process\n",
    "    localDate = datetime.datetime.now() - datetime.timedelta(hours = timeOffset)\n",
    "    localDateStart = localDate.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    localDatePrevious = localDate + datetime.timedelta(hours = timeOffset)\n",
    "    localDateStop = localDatePrevious.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    #utcDate = datetime.datetime.utcnow();\n",
    "    start = '2019-06-04T0:55:52Z' # fixed time stamp used for debugging\n",
    "    #start = localDateStart\n",
    "    #print(start)\n",
    "    stop = '2019-06-05T19:28:52Z' # fixed time stamp used for debugging\n",
    "    #stop = localDateStop\n",
    "    dataOffset = 0 # handle bad data engineering work - if you trust your data engineer set it to: 0\n",
    "    bufferLength = 30 # number of samples per overflow iteration evalution\n",
    "    levelThreshold = 0.45 # meters of water in pump pit\n",
    "    maxThreshold = 0.90 # meters of water in pump pit\n",
    "    levelSlopeAngle = 0.000085 # water increase factor in pump pit\n",
    "    resultAttribute = 'overflow' # explictly declare your result attribute\n",
    "    data, test = spongeCityService(start,stop,levelThreshold, maxThreshold, levelSlopeAngle,dataOffset,bufferLength,resultAttribute)\n",
    "    \n",
    "    # For Cloud command-line execution\n",
    "    #print(sys.argv[1:])\n",
    "    #pumpPitOverflowService(*sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
